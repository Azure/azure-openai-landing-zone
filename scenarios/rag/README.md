## Retrieval Augment Generation

Retrieval-augmented generation (RAG) for large language models (LLMs) aims to improve prediction quality by using an external datastore at inference time to build a richer prompt that includes some combination of context, history, and recent/relevant knowledge.
<img width="600"  src="../../media/RAG_Workflow.png">

### In Azure, RAG pattern is implemented with following components

<img width="600"  src="../../media/RAG_Components.png">

